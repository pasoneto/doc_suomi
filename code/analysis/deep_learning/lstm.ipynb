{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "typical-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as kb\n",
    "from PIL import Image\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, roc_auc_score, roc_curve\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "still-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleMaker_entry(sample, input_size, output_size):\n",
    "    n_slides = len(sample.index) - (output_size + input_size)+1\n",
    "    entrada = np.array([np.array(sample[entrada_var].iloc[i:i+input_size]) for i in range(0, n_slides, input_size)])\n",
    "    return entrada\n",
    "\n",
    "def sampleMaker_out(sample, input_size, output_size):\n",
    "    n_slides = len(sample.index) - (output_size + input_size)+1\n",
    "    saida = [sample[saida_var].iloc[i+input_size:i+input_size+output_size] for i in range(0, n_slides, input_size)]\n",
    "    return saida\n",
    "\n",
    "def splitter(data, group):\n",
    "    data = list(data.groupby(group))\n",
    "    data = [data[i][1] for i in range(len(data))]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv('/home/pasoneto/Documents/github/doc_suomi/data/lstm/lstm.csv')\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "base['valence_cat'] = le.fit_transform(base['valence_cat'])\n",
    "base['energy_cat'] = le.fit_transform(base['energy_cat'])\n",
    "base['loudness_cat'] = le.fit_transform(base['loudness_cat'])\n",
    "base['tempo_cat'] = le.fit_transform(base['tempo_cat'])\n",
    "\n",
    "\n",
    "base = splitter(base, \"album_id\")\n",
    "for i in base:\n",
    "    i.reset_index(drop = True, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "treino = base[0:int(len(base)*0.8)]\n",
    "teste = base[len(treino):len(base)]\n",
    "\n",
    "\n",
    "entrada_var   = ['danceability', 'energy', 'loudness_overall', 'mode_confidence','speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo_overall', 'duration_ms', 'time_signature_confidence', 'loudness_continuous', 'tempo_continuous', 'tempo_confidence', 'key_confidence', 'danceability_cum', 'energy_cum','loudness_overall_cum', 'speechiness_cum', 'acousticness_cum','instrumentalness_cum', 'liveness_cum', 'valence_cum','tempo_overall_cum', 'duration_ms_cum', 'time_signature_cum','loudness_continuous_cum', 'tempo_continuous_cum','tempo_confidence_cum', 'key_confidence_cum', 'mode_confidence_cum','time_signature_confidence_cum']\n",
    "saida_var     = ['tempo_cat'] #'energy_cat', 'loudness_cat', 'tempo_cat', 'album_id']\n",
    "\n",
    "entrada_treino = list(map(lambda x : sampleMaker_entry(x, 5, 1), treino))\n",
    "saida_treino   = list(map(lambda x : sampleMaker_out(x, 5, 1), treino))\n",
    "\n",
    "entrada_teste = list(map(lambda x : sampleMaker_entry(x, 5, 1), teste))\n",
    "saida_teste   = list(map(lambda x : sampleMaker_out(x, 5, 1), teste))\n",
    "\n",
    "import itertools\n",
    "entrada_treino = np.array(list(itertools.chain.from_iterable(entrada_treino)))\n",
    "saida_treino   = np.array(list(itertools.chain.from_iterable(saida_treino)))\n",
    "\n",
    "entrada_teste = np.array(list(itertools.chain.from_iterable(entrada_teste)))\n",
    "saida_teste   = np.array(list(itertools.chain.from_iterable(saida_teste)))\n",
    "\n",
    "# Definindo modelo\n",
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units = 60, return_sequences = True, activation = 'relu', input_shape = (entrada_treino.shape[1], 33)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 120, activation = 'sigmoid'))\n",
    "regressor.add(Dropout(0.5))\n",
    "\n",
    "regressor.add(Dense(units = 240, activation = 'sigmoid'))\n",
    "\n",
    "regressor.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "regressor.compile(optimizer = 'sgd', loss = \"binary_crossentropy\", \n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "# Fitando modelo\n",
    "regressor.fit(entrada_treino, saida_treino, epochs = 1500, batch_size = 120)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "previsores = list(itertools.chain.from_iterable(regressor.predict_classes(entrada_teste)))\n",
    "real = list(itertools.chain.from_iterable(list(itertools.chain.from_iterable(saida_teste))))\n",
    "probs = list(itertools.chain.from_iterable(regressor.predict_proba(entrada_teste)))\n",
    "\n",
    "print(\"Model: \", accuracy_score(previsores, real))\n",
    "\n",
    "\n",
    "# 0 greater\n",
    "# 1 smaller\n",
    "for i in range(len(previsores)):\n",
    "    for k in range(len(previsores[i])):\n",
    "        if previsores[i][k] == 0:\n",
    "            previsores[i][k] = np.mean(real[i])+np.random.uniform(0.08, 0.1)\n",
    "        if previsores[i][k] == 1:\n",
    "            previsores[i][k] = np.mean(real[i])-np.random.uniform(0.08, 0.1)\n",
    "    plt.plot(previsores[i], 'ro', color = 'red', label = 'Valencia prevista')\n",
    "    plt.plot(real[i], 'ro', color = 'blue', label = 'Valencia real')\n",
    "    plt.plot(previsores[i], color = 'red')\n",
    "    plt.plot(real[i], color = 'blue')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Saving model - Energy\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = regressor.to_json()\n",
    "with open(\"model_tempo.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "regressor.save_weights(\"model_tempo.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
