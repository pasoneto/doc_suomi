{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "randomForest 4.6-14\n",
      "\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "\n",
      "Attaching package: ‘randomForest’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    margin\n",
      "\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "\n",
      "Attaching package: ‘data.table’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    between, first, last\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘DescTools’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:data.table’:\n",
      "\n",
      "    %like%\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:caret’:\n",
      "\n",
      "    MAE, RMSE\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘tensorflow’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:caret’:\n",
      "\n",
      "    train\n",
      "\n",
      "\n",
      "`summarise()` regrouping output by 'album_id' (override with `.groups` argument)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to use datasets\n",
      " \n",
      "call    base()             for real values\n",
      "call    z_scored()         for normalized\n",
      "call    min_maxed()        for normalized2\n",
      "call    upsampled_album()  for binded upsamplped albums\n",
      "call    list_upsampled()   for list of upsampled albums\n",
      "call    low_z()            for normalized low level\n",
      "call    low_raw()          for raw  low level"
     ]
    }
   ],
   "source": [
    "setwd(\"/home/pasoneto/Documents/github/doc_suomi/code\")\n",
    "source(\"utils.R\")\n",
    "source(\"data_cook.R\")\n",
    "cat(howto_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing data for lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oi = upsampled_album()\n",
    "\n",
    "ltreino = (nrow(oi)/16)*0.8\n",
    "lteste = (nrow(oi)/16)*0.2\n",
    "\n",
    "colnames(oi) <- c(\"track_number\", \"album_id\", \"valence\", \"energy\", \"loudness\", \"tempo\")\n",
    "\n",
    "treino = oi[1:(ltreino*16)]\n",
    "teste = oi[((ltreino*16)+1):nrow(oi)]\n",
    "\n",
    "(nrow(treino)+nrow(teste))==nrow(oi)\n",
    "\n",
    "write.csv(treino, \"/home/pasoneto/Documents/github/doc_suomi/data/treated_data/lstm_treino_teste/treino.csv\")\n",
    "write.csv(teste, \"/home/pasoneto/Documents/github/doc_suomi/data/treated_data/lstm_treino_teste/teste.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing data for dissimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"tidyverse\")\n",
    "\n",
    "#Import list of dissimilarities\n",
    "oi = list_upsampled() #upsampled using bilinear interpolation\n",
    "\n",
    "# #Renaming columns and resetting track_number\n",
    "for(i in 1:length(oi)){\n",
    "    oi[[i]]$`0` <- seq(1, 16, 1)\n",
    "    colnames(oi[[i]]) <- c(\"track_number\", \"album_id\", \"valence\", \"energy\", \"loudness\", \"tempo\")\n",
    "}\n",
    "\n",
    "#Generating dissimilarities\n",
    "albums = dissim_gen(oi)\n",
    "\n",
    "#Binding albums\n",
    "albums = do.call(rbind, albums)\n",
    "\n",
    "#Remaking track numbers\n",
    "albums = data.frame(albums)\n",
    "albums$track_number = rep(seq(1, 16, 1), length(oi) )\n",
    "\n",
    "#Removing NAs\n",
    "ha <- split(albums, seq(nrow(albums)))\n",
    "for(i in 1:length(ha)){\n",
    "    ha[[i]] <- as.list(ha[[i]])\n",
    "}\n",
    "\n",
    "for(i in 1:length(ha)){\n",
    "    ha[[i]] = unlist(ha[[i]], use.names = FALSE)[!is.na(unlist(ha[[i]], use.names = FALSE))]\n",
    "}\n",
    "#####Removing tracks with too many NAs (due to upsampling)\n",
    "final = c()\n",
    "for(i in 1:length(ha)){\n",
    "    if(length(ha[[i]]) == 16){\n",
    "        final[[i]] = ha[[i]]\n",
    "    }\n",
    "}\n",
    "\n",
    "final <- rlist::list.rbind(final)\n",
    "final <- data.frame(final)\n",
    "colnames(final) <- c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\", \"x10\", \"x11\", \"x12\", \"x13\", \"x14\", \"x15\", \"track_number\")\n",
    "\n",
    "final$position = \"middle\"\n",
    "for(i in 1:NROW(final)){\n",
    "       if(final$track_number[[i]] == 1){\n",
    "           final$position[[i]] = \"edge\"\n",
    "       }\n",
    "       if(final$track_number[[i]] == 16){\n",
    "            final$position[[i]] = \"edge\"\n",
    "       }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge = final %>% filter(position == \"edge\")\n",
    "middle = final %>% filter(position == \"middle\") %>% dplyr::sample_n(8890)\n",
    "\n",
    "overall = bind_rows(middle, edge)\n",
    "\n",
    "## 75% of the sample size\n",
    "smp_size <- floor(0.75 * nrow(overall))\n",
    "train_ind <- sample(seq_len(nrow(overall)), size = smp_size)\n",
    "\n",
    "## Separating\n",
    "train <- overall[train_ind, ]\n",
    "train %<>% select(!track_number)\n",
    "test <- overall[-train_ind, ]\n",
    "test %<>% select(!track_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "write.csv(train, \"/home/pasoneto/Documents/github/doc_suomi/data/treated_data/classificacao_edges/train.csv\")\n",
    "write.csv(test, \"/home/pasoneto/Documents/github/doc_suomi/data/treated_data/classificacao_edges/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writting for later usage\n",
    "write.csv(final, \"/home/pasoneto/Documents/github/doc_suomi/data/treated_data/classificacao_edges/classificacao_edges.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writting dissimilarities 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = z_scored()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dissim_by_track <- function(dt, colname) {\n",
    "    colname <- enquo(colname) \n",
    "    dt %>% \n",
    "        select(!!colname) %>%\n",
    "        as.matrix() %>% \n",
    "        cluster::daisy() %>%\n",
    "        as.matrix() %>% \n",
    "        colMeans() -> result \n",
    "    return(result)\n",
    "}\n",
    "\n",
    "edge_detector =\n",
    "    function(d){\n",
    "        for(i in 1:NROW(d)){\n",
    "               if(d$track_number[[i]] == 1){\n",
    "                   d$position[[i]] = \"edge\"\n",
    "               }\n",
    "               if(d$track_number[[i]] == NROW(d)){\n",
    "                    d$position[[i]] = \"edge\"\n",
    "               }\n",
    "        }\n",
    "        return(d$position)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt$position = \"middle\"\n",
    "dt = split(dt, dt$album_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(i in 1:length(dt)){\n",
    "    \n",
    "    dt[[i]]$valence = dissim_by_track(dt[[i]], valence)\n",
    "    dt[[i]]$energy = dissim_by_track(dt[[i]], energy)\n",
    "    dt[[i]]$loudness = dissim_by_track(dt[[i]], loudness)\n",
    "    dt[[i]]$tempo = dissim_by_track(dt[[i]], tempo)\n",
    "    \n",
    "    dt[[i]]$position = edge_detector(dt[[i]])\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dplyr::bind_rows(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 75% of the sample size\n",
    "smp_size <- floor(0.75 * nrow(dt))\n",
    "train_ind <- sample(seq_len(nrow(dt)), size = smp_size)\n",
    "\n",
    "# ## Separating\n",
    "train <- dt[train_ind, ]\n",
    "train %<>% select(!track_number)\n",
    "test <- dt[-train_ind, ]\n",
    "test %<>% select(!track_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "write.csv(train, \"/home/pasoneto/Documents/github/doc_suomi/data/treated_data/classificacao_edges/train.csv\")\n",
    "write.csv(test, \"/home/pasoneto/Documents/github/doc_suomi/data/treated_data/classificacao_edges/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writting data for low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`mutate_if()` ignored the following grouping variables:\n",
      "Column `album_id`\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oi = low_minmax()\n",
    "oi %<>% \n",
    "    group_by(track_id) %>%\n",
    "    mutate(nsamples = NROW(valence)) %>%\n",
    "    filter(nsamples < 5)\n",
    "a_out <- unique(oi$album_id)\n",
    "data = low_minmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`summarise()` regrouping output by 'album_id', 'track_id' (override with `.groups` argument)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data %<>%\n",
    "    filter(!album_id %in% a_out) %>% \n",
    "    ungroup() %>%\n",
    "    group_by(track_id) %>%\n",
    "    mutate(track_section = seq(1, NROW(track_id), 1)) %>%\n",
    "    mutate(track_section = lsr::quantileCut(track_section, 5, labels = c(\"a\", \"b\", \"c\", \"d\", \"e\"))) %>%\n",
    "    ungroup() %>% group_by(album_id, track_id, track_section) %>%\n",
    "    summarise(danceability = mean(danceability),\n",
    "              energy = mean(energy), \n",
    "              loudness_overall = mean(loudness_overall),\n",
    "              speechiness = mean(speechiness),\n",
    "              acousticness = mean(acousticness),\n",
    "              instrumentalness = mean(instrumentalness), \n",
    "              liveness = mean(liveness),\n",
    "              valence = mean(valence),\n",
    "              tempo_overall = mean(tempo_overall), \n",
    "              duration_ms = mean(duration_ms),\n",
    "              time_signature = mean(time_signature),\n",
    "              track_number = mean(track_number), \n",
    "              loudness_continuous = mean(loudness_continuous),\n",
    "              tempo_continuous = mean(tempo_continuous), \n",
    "              tempo_confidence = mean(tempo_confidence), \n",
    "              key_confidence = mean(key_confidence),\n",
    "              mode_confidence = mean(mode_confidence), \n",
    "              time_signature_confidence = mean(time_signature_confidence)) %>%\n",
    "    ungroup() %>%\n",
    "    arrange(album_id) %>% select(!track_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`summarise()` regrouping output by 'album_id' (override with `.groups` argument)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data %>%\n",
    "    group_by(album_id, track_id) %>%\n",
    "    summarise(danceability_cum = mean(danceability),\n",
    "           energy_cum = mean(energy),\n",
    "           loudness_overall_cum = mean(loudness_overall),\n",
    "           speechiness_cum = mean(speechiness),\n",
    "           acousticness_cum = mean(acousticness),\n",
    "           instrumentalness_cum = mean(instrumentalness), \n",
    "           liveness_cum = mean(liveness),\n",
    "           valence_cum = mean(valence),\n",
    "           tempo_overall_cum = mean(tempo_overall), \n",
    "           duration_ms_cum = mean(duration_ms),\n",
    "           time_signature_cum = mean(time_signature),\n",
    "           loudness_continuous_cum = mean(loudness_continuous),\n",
    "           tempo_continuous_cum = mean(tempo_continuous),\n",
    "           tempo_confidence_cum = mean(tempo_confidence),\n",
    "           key_confidence_cum = mean(key_confidence),\n",
    "           mode_confidence_cum = mean(mode_confidence),\n",
    "           time_signature_confidence_cum = mean(time_signature_confidence)) %>%\n",
    "    ungroup() %>% group_by(album_id) %>%\n",
    "    mutate(danceability_cum = cumsum(danceability_cum),\n",
    "           energy_cum = cumsum(energy_cum),\n",
    "           loudness_overall_cum = cumsum(loudness_overall_cum),\n",
    "           speechiness_cum = cumsum(speechiness_cum),\n",
    "           acousticness_cum = cumsum(acousticness_cum),\n",
    "           instrumentalness_cum = cumsum(instrumentalness_cum), \n",
    "           liveness_cum = cumsum(liveness_cum),\n",
    "           valence_cum = cumsum(valence_cum),\n",
    "           tempo_overall_cum = cumsum(tempo_overall_cum), \n",
    "           duration_ms_cum = cumsum(duration_ms_cum),\n",
    "           time_signature_cum = cumsum(time_signature_cum),\n",
    "           loudness_continuous_cum = cumsum(loudness_continuous_cum),\n",
    "           tempo_continuous_cum = cumsum(tempo_continuous_cum),\n",
    "           tempo_confidence_cum = cumsum(tempo_confidence_cum),\n",
    "           key_confidence_cum = cumsum(key_confidence_cum),\n",
    "           mode_confidence_cum = cumsum(mode_confidence_cum),\n",
    "           time_signature_confidence_cum = cumsum(time_signature_confidence_cum)) -> cummed\n",
    "#           write.csv(\"/home/pasoneto/Documents/github/doc_suomi/data/lstm/lstm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "oi = merge(x = cummed, y = data, by.x = c(\"album_id\", \"track_id\"), by.y = c(\"album_id\", \"track_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in if (x[i + 1] > x[i]) {: argument is of length zero\n",
     "output_type": "error",
     "traceback": [
      "Error in if (x[i + 1] > x[i]) {: argument is of length zero\nTraceback:\n",
      "1. greater(c(1, 2, 3))"
     ]
    }
   ],
   "source": [
    "greater = function(x){\n",
    "    for(i in 1:length(x)-1){ \n",
    "        if(x[[i+1]] > x[[i]]){\n",
    "            x[\n",
    "            ] <- 'greater'            \n",
    "        } else{\n",
    "            x[i] <- 'smaller'\n",
    "        }\n",
    "    }\n",
    "    return(x)\n",
    "}\n",
    "greater(c(1, 2, 3))\n",
    "# oi %<>% \n",
    "#     mutate(danceability_cum = minmax(danceability_cum, 1, 2),\n",
    "#            energy_cum = minmax(energy_cum, 1, 2),\n",
    "#            loudness_overall_cum = minmax(loudness_overall_cum, 1, 2),\n",
    "#            speechiness_cum = minmax(speechiness_cum, 1, 2),\n",
    "#            acousticness_cum = minmax(acousticness_cum, 1, 2),\n",
    "#            instrumentalness_cum = minmax(instrumentalness_cum, 1, 2), \n",
    "#            liveness_cum = minmax(liveness_cum, 1, 2),\n",
    "#            valence_cum = minmax(valence_cum, 1, 2),\n",
    "#            tempo_overall_cum = minmax(tempo_overall_cum, 1, 2), \n",
    "#            duration_ms_cum = minmax(duration_ms_cum, 1, 2),\n",
    "#            time_signature_cum = minmax(time_signature_cum, 1, 2),\n",
    "#            loudness_continuous_cum = minmax(loudness_continuous_cum, 1, 2),\n",
    "#            tempo_continuous_cum = minmax(tempo_continuous_cum, 1, 2),\n",
    "#            tempo_confidence_cum = minmax(tempo_confidence_cum, 1, 2),\n",
    "#            key_confidence_cum = minmax(key_confidence_cum, 1, 2),\n",
    "#            mode_confidence_cum = minmax(mode_confidence_cum, 1, 2),\n",
    "#            time_signature_confidence_cum = minmax(time_signature_confidence_cum, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: Problem with `mutate()` input `haha`.\n\u001b[31m✖\u001b[39m argument is of length zero\n\u001b[34mℹ\u001b[39m Input `haha` is `greater(energy)`.\n\u001b[34mℹ\u001b[39m The error occurred in group 1: album_id = \"007bD7YMU5GUUNzNWKGfoV\".\n",
     "output_type": "error",
     "traceback": [
      "Error: Problem with `mutate()` input `haha`.\n\u001b[31m✖\u001b[39m argument is of length zero\n\u001b[34mℹ\u001b[39m Input `haha` is `greater(energy)`.\n\u001b[34mℹ\u001b[39m The error occurred in group 1: album_id = \"007bD7YMU5GUUNzNWKGfoV\".\nTraceback:\n",
      "1. oi %>% group_by(album_id) %>% mutate(haha = greater(energy))",
      "2. mutate(., haha = greater(energy))",
      "3. mutate.data.frame(., haha = greater(energy))",
      "4. mutate_cols(.data, ...)",
      "5. withCallingHandlers({\n .     for (i in seq_along(dots)) {\n .         not_named <- (is.null(dots_names) || dots_names[i] == \n .             \"\")\n .         chunks <- NULL\n .         result <- NULL\n .         if (quo_is_symbol(dots[[i]])) {\n .             name <- as_string(quo_get_expr(dots[[i]]))\n .             if (name %in% names(new_columns)) {\n .                 result <- new_columns[[name]]\n .                 chunks <- mask$get_resolved(name)\n .             }\n .             else if (name %in% names(.data)) {\n .                 result <- .data[[name]]\n .                 chunks <- mask$resolve(name)\n .             }\n .             if (inherits(.data, \"rowwise_df\") && vec_is_list(result)) {\n .                 sizes <- list_sizes(result)\n .                 wrong <- which(sizes != 1)\n .                 if (length(wrong)) {\n .                   group <- wrong[1L]\n .                   mask$set_current_group(group)\n .                   abort(x_size = sizes[group], class = \"dplyr:::mutate_incompatible_size\")\n .                 }\n .             }\n .         }\n .         if (is.null(chunks)) {\n .             chunks <- mask$eval_all_mutate(dots[[i]])\n .         }\n .         mask$across_cache_reset()\n .         if (is.null(chunks)) {\n .             if (!is.null(dots_names) && dots_names[i] != \"\") {\n .                 new_columns[[dots_names[i]]] <- zap()\n .                 mask$remove(dots_names[i])\n .             }\n .             next\n .         }\n .         if (is.null(result)) {\n .             if (length(rows) == 1) {\n .                 result <- chunks[[1]]\n .             }\n .             else {\n .                 result <- withCallingHandlers(vec_unchop(chunks, \n .                   rows), vctrs_error_incompatible_type = function(cnd) {\n .                   abort(class = \"dplyr:::error_mutate_incompatible_combine\", \n .                     parent = cnd)\n .                 })\n .             }\n .         }\n .         if (not_named && is.data.frame(result)) {\n .             new_columns[names(result)] <- result\n .             map2(seq_along(result), names(result), function(i, \n .                 nm) {\n .                 mask$add(nm, pluck(chunks, i))\n .             })\n .         }\n .         else {\n .             name <- if (not_named) \n .                 auto_named_dots[i]\n .             else dots_names[i]\n .             new_columns[[name]] <- result\n .             mask$add(name, chunks)\n .         }\n .     }\n . }, error = function(e) {\n .     local_call_step(dots = dots, .index = i, .fn = \"mutate\", \n .         .dot_data = inherits(e, \"rlang_error_data_pronoun_not_found\"))\n .     call_step_envir <- peek_call_step()\n .     error_name <- call_step_envir$error_name\n .     error_expression <- call_step_envir$error_expression\n .     show_group_details <- TRUE\n .     if (inherits(e, \"dplyr:::mutate_incompatible_size\")) {\n .         size <- vec_size(rows[[i]])\n .         x_size <- e$x_size\n .         bullets <- c(x = glue(\"Input `{error_name}` can't be recycled to size {size}.\"), \n .             i = cnd_bullet_input_info(), i = glue(\"Input `{error_name}` must be size {or_1(size)}, not {x_size}.\"), \n .             i = cnd_bullet_rowwise_unlist())\n .     }\n .     else if (inherits(e, \"dplyr:::mutate_mixed_null\")) {\n .         show_group_details <- FALSE\n .         bullets <- c(x = glue(\"`{error_name}` must return compatible vectors across groups.\"), \n .             i = cnd_bullet_input_info(), i = \"Cannot combine NULL and non NULL results.\", \n .             i = cnd_bullet_rowwise_unlist())\n .     }\n .     else if (inherits(e, \"dplyr:::mutate_not_vector\")) {\n .         bullets <- c(x = glue(\"Input `{error_name}` must be a vector, not {friendly_type_of(e$result)}.\"), \n .             i = cnd_bullet_input_info(), i = cnd_bullet_rowwise_unlist())\n .     }\n .     else if (inherits(e, \"dplyr:::error_mutate_incompatible_combine\")) {\n .         show_group_details <- FALSE\n .         bullets <- c(x = glue(\"Input `{error_name}` must return compatible vectors across groups\"), \n .             i = cnd_bullet_input_info(), i = cnd_bullet_combine_details(e$parent$x, \n .                 e$parent$x_arg), i = cnd_bullet_combine_details(e$parent$y, \n .                 e$parent$y_arg))\n .     }\n .     else {\n .         bullets <- c(x = conditionMessage(e), i = cnd_bullet_input_info())\n .     }\n .     abort(c(cnd_bullet_header(), bullets, i = if (show_group_details) cnd_bullet_cur_group_label()), \n .         class = c(\"dplyr:::mutate_error\", \"dplyr_error\"), error_name = error_name, \n .         error_expression = error_expression)\n . }, warning = function(w) {\n .     local_call_step(dots = dots, .index = i, .fn = \"mutate\")\n .     warn(c(cnd_bullet_header(), i = conditionMessage(w), i = cnd_bullet_input_info(), \n .         i = cnd_bullet_cur_group_label()))\n . })",
      "6. mask$eval_all_mutate(dots[[i]])",
      "7. greater(energy)",
      "8. .handleSimpleError(function (e) \n . {\n .     local_call_step(dots = dots, .index = i, .fn = \"mutate\", \n .         .dot_data = inherits(e, \"rlang_error_data_pronoun_not_found\"))\n .     call_step_envir <- peek_call_step()\n .     error_name <- call_step_envir$error_name\n .     error_expression <- call_step_envir$error_expression\n .     show_group_details <- TRUE\n .     if (inherits(e, \"dplyr:::mutate_incompatible_size\")) {\n .         size <- vec_size(rows[[i]])\n .         x_size <- e$x_size\n .         bullets <- c(x = glue(\"Input `{error_name}` can't be recycled to size {size}.\"), \n .             i = cnd_bullet_input_info(), i = glue(\"Input `{error_name}` must be size {or_1(size)}, not {x_size}.\"), \n .             i = cnd_bullet_rowwise_unlist())\n .     }\n .     else if (inherits(e, \"dplyr:::mutate_mixed_null\")) {\n .         show_group_details <- FALSE\n .         bullets <- c(x = glue(\"`{error_name}` must return compatible vectors across groups.\"), \n .             i = cnd_bullet_input_info(), i = \"Cannot combine NULL and non NULL results.\", \n .             i = cnd_bullet_rowwise_unlist())\n .     }\n .     else if (inherits(e, \"dplyr:::mutate_not_vector\")) {\n .         bullets <- c(x = glue(\"Input `{error_name}` must be a vector, not {friendly_type_of(e$result)}.\"), \n .             i = cnd_bullet_input_info(), i = cnd_bullet_rowwise_unlist())\n .     }\n .     else if (inherits(e, \"dplyr:::error_mutate_incompatible_combine\")) {\n .         show_group_details <- FALSE\n .         bullets <- c(x = glue(\"Input `{error_name}` must return compatible vectors across groups\"), \n .             i = cnd_bullet_input_info(), i = cnd_bullet_combine_details(e$parent$x, \n .                 e$parent$x_arg), i = cnd_bullet_combine_details(e$parent$y, \n .                 e$parent$y_arg))\n .     }\n .     else {\n .         bullets <- c(x = conditionMessage(e), i = cnd_bullet_input_info())\n .     }\n .     abort(c(cnd_bullet_header(), bullets, i = if (show_group_details) cnd_bullet_cur_group_label()), \n .         class = c(\"dplyr:::mutate_error\", \"dplyr_error\"), error_name = error_name, \n .         error_expression = error_expression)\n . }, \"argument is of length zero\", base::quote(if (x[i + 1] > x[i]) {\n .     x[i] <- \"greater\"\n . } else {\n .     x[i] <- \"smaller\"\n . }))   # at line 3-7 of file <text>",
      "9. h(simpleError(msg, call))",
      "10. abort(c(cnd_bullet_header(), bullets, i = if (show_group_details) cnd_bullet_cur_group_label()), \n  .     class = c(\"dplyr:::mutate_error\", \"dplyr_error\"), error_name = error_name, \n  .     error_expression = error_expression)",
      "11. signal_abort(cnd)"
     ]
    }
   ],
   "source": [
    "oi %>% group_by(album_id) %>%\n",
    "    mutate(haha = greater(energy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
